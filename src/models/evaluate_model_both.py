import tensorflow as tf
import pandas as pd
import src.tools.tools as tools 
import src.models.models as models
from src.models.metrics import SparseF1Score
import os 
import logging 
import numpy as np
from sklearn.metrics import classification_report
import json

def load_dataset() -> tuple:
    """
    Load the test dataset generated by ./src/data/make_dataset.py.
    Returns:
        X_test (DataFrame): The test dataset containing features.
        y_test (DataFrame): The test dataset containing labels.
    """
    try:
        X_test = pd.read_csv(os.path.join(tools.DATA_PROCESSED_DIR, "X_test.csv"), index_col=0)
        y_test = pd.read_csv(os.path.join(tools.DATA_PROCESSED_DIR, "y_test.csv"), index_col=0)

    except FileNotFoundError as e:
        logging.error(f"File not found: {e}")
        raise
    except Exception as e:
        logging.error(f"An error occurred while loading datasets: {e}")
        raise
    # Ensure that the 'feature' column exists in X_test
    if 'feature' not in X_test.columns:
        logging.error("The 'feature' column is missing in the X_test dataset.")
        raise ValueError("The 'feature' column is missing in the X_test dataset.")
    # Ensure that the 'prdtypecode' column exists in y_test
    if 'prdtypecode' not in y_test.columns:
        logging.error("The 'prdtypecode' column is missing in the y_test dataset.")
        raise ValueError("The 'prdtypecode' column is missing in the y_test dataset.")
    # Ensure that the 'prdtypecode' column is of integer type
    if not pd.api.types.is_integer_dtype(y_test['prdtypecode']):
        logging.error("The 'prdtypecode' column must be of integer type.")
        raise ValueError("The 'prdtypecode' column must be of integer type.")
    # Ensure that the 'feature' column is of string type
    if not pd.api.types.is_string_dtype(X_test['feature']):
        logging.error("The 'feature' column must be of string type.")
        raise ValueError("The 'feature' column must be of string type.")
    return X_test, y_test


def main():
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    logging.info("Available GPUs: %s", tf.config.list_physical_devices('GPU'))
    
    # Load dataset parameters from YAML file
    params = tools.load_dataset_params_from_yaml()

    logger.info("Loading dataset for prediction...")
    # Load the X_test dataset
    X_test, y_test = load_dataset()
    # Check if the dataset was loaded successfully
    if X_test is None or y_test is None:
        logger.error("Failed to load dataset.")
        exit(1)

   # Load the MAX LEN and MODEL_NAME from params
    MAX_LEN = params['models_parameters']['Camembert']['max_length']
    if not isinstance(MAX_LEN, int) or MAX_LEN <= 0:
        logging.error(f"Invalid max_len value: {MAX_LEN}. It should be a positive integer.")
        raise ValueError(f"Invalid max_len value: {MAX_LEN}. It should be a positive integer.")
    MODEL_NAME = params['models_parameters']['Camembert']['model_name']
    if not isinstance(MODEL_NAME, str) or not MODEL_NAME:   
        logging.error(f"Invalid MODEL_NAME value: {MODEL_NAME}. It should be a non-empty string.")
        raise ValueError(f"Invalid MODEL_NAME value: {MODEL_NAME}. It should be a non-empty string.")

    # Load BATCH_SIZE from params
    BATCH_SIZE = params['training_parameters']['batch_size']
    if not isinstance(BATCH_SIZE, int) or BATCH_SIZE <= 0:
        logging.error(f"Invalid BATCH_SIZE value: {BATCH_SIZE}. It should be a positive integer.")
        raise ValueError(f"Invalid BATCH_SIZE value: {BATCH_SIZE}. It should be a positive integer.")

    nb_trainable_layers = params['models_parameters']['EfficientNetB1']['nb_trainable_layers']
    if not isinstance(nb_trainable_layers, int) or nb_trainable_layers < 0:
        logging.error(f"Invalid nb_trainable_layers value: {nb_trainable_layers}. It should be a non-negative integer.")
        raise ValueError(f"Invalid nb_trainable_layers value: {nb_trainable_layers}. It should be a non-negative integer.")    

    # Load the Camembert tokenizer and encode function
    logging.info("Loading Camembert tokenizer and encode function...")
    encode = models.load_encode_data(MODEL_NAME=MODEL_NAME, MAX_LEN=MAX_LEN)
    if encode is None:
        logging.error("Failed to load the encode function.")
        raise ValueError("Failed to load the encode function.")

    logging.info("Creating TensorFlow datasets for training and validation...")
    # Convert the training and validation datasets to TensorFlow datasets
    test_dataset = tf.data.Dataset.from_tensor_slices((X_test.feature.tolist(),
                                                        X_test.image_path.tolist(),
                                                        y_test.prdtypecode.tolist())
                                                        ).map(encode).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    logging.info("TensorFlow dataset created successfully.")

    # Load the Camembert model for multi-class classification prepared for prediction
    logging.info("Building the Camembert model for prediction...")
    model = models.build_merged_model(MODEL_NAME=MODEL_NAME, 
                                      MAX_LEN=MAX_LEN, 
                                      NUM_CLASSES=tools.NUM_CLASSES,
                                      nb_trainable_layers=nb_trainable_layers)
    if model is None:
        logging.error("Failed to build the Camembert model.")
        raise ValueError("Failed to build the Camembert model.")
    logging.info("Camembert model built successfully.")

#    model.load_weights = True  # Set to True to load the model weights for prediction
    # Check if the model weights file exists

    if not os.path.exists(tools.MODEL_DIR):
        logging.error(f"Model directory does not exist: {tools.MODEL_DIR}")
        raise FileNotFoundError(f"Model directory does not exist: {tools.MODEL_DIR}")

    weights_file = os.path.join(tools.MODEL_DIR, "merged_model.weights.h5")
    if  os.path.exists(weights_file):
        model.load_weights(weights_file)
        logging.info("Model weights loaded successfully.")
    else:
        logging.error(f"Model weights file not found: {weights_file}")
        raise FileNotFoundError(f"Model weights file not found: {weights_file}")
    # Make predictions
    logging.info("Making predictions on the test dataset...")
    predictions = model.predict(test_dataset)
    logging.info("Predictions made successfully.")
    # Convert predictions to class labels
    y_pred = np.argmax(predictions, -1)
    logging.info("Predicted classes obtained successfully.")
    # Convert y_test to numpy array for evaluation
    # Load the mapping dictionary to convert integer labels back to prdtypecode
    dict_mapping_reverse = tools.load_reverse_mapping_dict()
    if dict_mapping_reverse is None:
        logging.error("Failed to load the reverse mapping dictionary.")
        raise ValueError("Failed to load the reverse mapping dictionary.")
    # Convert integer predictions to prdtypecode using the reverse mapping dictionary
    y_pred_prdtypecode = [dict_mapping_reverse.get(pred, "Unknown") for pred in y_pred]
    logging.info("Converted predicted classes to prdtypecode successfully.")
    # Convert y_test to numpy array for evaluation
    y_test_prdtypecode = y_test.prdtypecode.tolist()
    y_test_prdtypecode = [dict_mapping_reverse.get(label, "Unknown") for label in y_test_prdtypecode]
    report_dict = classification_report(y_test_prdtypecode, y_pred_prdtypecode, output_dict=True, zero_division=0)
    logging.info("Classification report generated successfully.")
    # Convert report to DataFrame for better visualization
    report_df = pd.DataFrame(report_dict).transpose()
    # Save the classification report to a CSV file
    os.makedirs(tools.METRICS_DIR, exist_ok=True)  # Ensure the metrics directory exists
    report_path = os.path.join(tools.METRICS_DIR, "classification_report_text.csv")
    report_df.to_csv(report_path)
    logging.info(f"Classification report saved to {report_path}")
    logging.info("Prediction process completed successfully.")

    # Save the predictions to a CSV file
    logging.info("Saving predictions to CSV file...")
    predictions_df = pd.DataFrame({
        'image_id': X_test.index,
        'predicted_prdtypecode': y_pred_prdtypecode
    })
    predictions_path = os.path.join(tools.DATA_PROCESSED_DIR, "predictions_text.csv")
    predictions_df.to_csv(predictions_path, index=False)
    logging.info(f"Predictions saved to {predictions_path}")

    # Save the classification report to a JSON file
    logging.info("Saving classification report to JSON file...")
    # Save the classification report as a JSON file
    report_json_path = os.path.join(tools.METRICS_DIR, "classification_report_text.json")
    with open(report_json_path, "w", encoding="utf-8") as f:
        json.dump(report_dict, f, ensure_ascii=True, indent=4)
    logging.info(f"Classification report saved to {report_json_path}")    

if __name__ == "__main__":
    main()
else:
    import inspect

    # If this script is imported, run the main function only if it is called from evaluate_model.py
    stack = inspect.stack()
    for frame in stack:
        if "evaluate_model.py" in frame.filename:
            main()
            break


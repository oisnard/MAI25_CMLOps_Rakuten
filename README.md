MAI25_CMLOPS : project Rakuten 
==============================

Projet pÃ©dagogique rÃ©alisÃ© dans le cadre de la formation MLOps de DataScientest (Cohorte MAI 2025), axÃ© sur la mise en place dâ€™une architecture MLOps complÃ¨te pour le traitement et la classification de donnÃ©es produits Rakuten dans le cadre du challenge ens-data : https://challengedata.ens.fr/participants/challenges/35/ .
Les modÃ¨les dÃ©ployÃ©s sont dÃ©rivÃ©s de ceux dÃ©finis par l'Ã©quipe Olivier ISNARD / Julien TREVISAN / LoÃ¯c RAMAYE lors de leur formation Data Scientist (cohorte Juin 2025) et qui avaient permis d'obtenir la premiÃ¨re place au classement public et privÃ© du challenge. Dans le cadre de ce projet, des modÃ¨les plus lÃ©gers ont Ã©tÃ© mises en place afin de rÃ©duire les coÃ»ts d'instance AWS (dÃ©ploiement sur instance EC2 avec GPU).


---
## ğŸš€ Objectifs rÃ©alisÃ©s 

- Mettre en place un pipeline complet de Machine Learning avec Airflow.
- IntÃ©grer des Ã©tapes de data loading, preprocessing, entraÃ®nement, Ã©valuation et dÃ©ploiement.
- Suivre les expÃ©riences via MLflow.
- Conteneuriser lâ€™environnement avec Docker.
- Fournir une API de prÃ©diction REST sÃ©curisÃ©e.
- Suivre les versions de donnÃ©es avec DVC
- Tests unitaires

---
## ğŸ§­ SchÃ©ma dâ€™Architecture MLOps simplifiÃ©
![alt text](/data/dataviz/schema_archi.png)

---
## ğŸ“ Structure du dÃ©pÃ´t

```bash
.
â”œâ”€â”€ airflow/                   # Composants liÃ©s Ã  Airflow
â”‚   â”œâ”€â”€ dags/                 # DAG principal orchestrant le pipeline
â”‚   â”‚   â””â”€â”€ rakuten_dags.py
â”‚
â”œâ”€â”€ data/                     # DonnÃ©es versionnÃ©es avec DVC
â”‚   â”œâ”€â”€ raw/                 # DonnÃ©es brutes (ex : images, CSV initiaux)
â”‚   â”œâ”€â”€ processed/           # DonnÃ©es traitÃ©es (X_train, y_train, etc.)
â”‚   â”œâ”€â”€ processed.dvc        # Fichier DVC de suivi de `/processed`
â”‚   â”œâ”€â”€ raw.dvc              # Fichier DVC de suivi de `/raw`
â”‚   â””â”€â”€ .gitignore           # Ã‰vite de traquer les gros fichiers localement
â”‚
â”œâ”€â”€ docker/                   # Dockerfiles spÃ©cifiques Ã  chaque Ã©tape
â”‚   â”œâ”€â”€ prometheus.yml        # Configuration du service Prometheus
|   â”œâ”€â”€ Dockerfile.airflow
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.dataloading
â”‚   â”œâ”€â”€ Dockerfile.evaluate
â”‚   â”œâ”€â”€ Dockerfile.mlflow
â”‚   â”œâ”€â”€ Dockerfile.preprocessing
â”‚   â”œâ”€â”€ Dockerfile.train
â”‚   â”œâ”€â”€ requirements-airflow.txt     # DÃ©pendances Airflow
â”‚   â”œâ”€â”€ requirements-api.txt         # DÃ©pendances FastAPI
â”‚   â”œâ”€â”€ requirements-dataloading.txt
â”‚   â”œâ”€â”€ requirements-evaluate.txt
â”‚   â”œâ”€â”€ requirements-mlflow.txt
â”‚   â”œâ”€â”€ requirements-preprocessing.txt
â”‚   â””â”€â”€ requirements-train.txt
â”œâ”€â”€ docker-compose-template.yml        # Template du docker compose pour gÃ©nÃ©rer docker compose selon GPU ou CPU (selon fichier .env)
â”œâ”€â”€ docker-compose.yml                 # Orchestration des services via Docker Compose
â”‚
â”œâ”€â”€ models/                   # ModÃ¨les entraÃ®nÃ©s (.pkl ou autres)
â”‚
â”œâ”€â”€ mlruns/                   # RÃ©pertoire dâ€™expÃ©rimentation MLflow (tracking local)
â”‚
â”œâ”€â”€ params.yaml               # ParamÃ¨tres globaux pour le pipeline (modÃ¨le, seed, split, etc.)
â”‚
â”œâ”€â”€ src/                      # Code source modulaire pour chaque Ã©tape
â”‚   â”œâ”€â”€ dataloading/         # Scripts pour charger les donnÃ©es brutes
â”‚   â”œâ”€â”€ preprocessing/       # Feature engineering, normalisation, etc.
â”‚   â”œâ”€â”€ training/            # EntraÃ®nement de modÃ¨les
â”‚   â”œâ”€â”€ evaluation/          # Ã‰valuation de performance
â”‚   â””â”€â”€ utils/               # Fonctions utilitaires (log, I/O, etc.)
â”‚
â”œâ”€â”€ tests/                    # Tests unitaires Pytest pour chaque module
â”‚   â”œâ”€â”€ test_dataloading.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_training.py
â”‚   â”œâ”€â”€ test_evaluation.py
â”‚   â””â”€â”€ conftest.py
â”‚
â”œâ”€â”€ .dvc/                     # RÃ©pertoire interne de configuration DVC
â”œâ”€â”€ .dvcignore                # Ã‰quiv. de .gitignore pour DVC
â”œâ”€â”€ .env                      # Variables dâ€™environnement (ex: BASE_DIR)
â””â”€â”€ README.md                 # Documentation du projet (ce fichier)
```
ğŸ” Fichiers de configuration importants
| Fichier              | RÃ´le                                                           |
| -------------------- | -------------------------------------------------------------- |
| `docker-compose.yml` | Lance tous les services nÃ©cessaires (Airflow, API, MLflowâ€¦)    |
| `params.yaml`        | Centralise les hyperparamÃ¨tres, chemins, splits, etc.          |
| `processed.dvc`      | Suit les transformations de donnÃ©es via DVC                    |
| `.dvcignore`         | Exclut certains fichiers des suivis DVC                        |
| `.env`               | DÃ©finit les variables dâ€™environnement Docker (base\_dir, etc.) |
<br>Pour gÃ©nÃ©rer le fichier docker-compose.yml Ã  partir du `docker-compose-template.yml`, il faut exÃ©cuter la commande : 
```
set -a && source .env && set +a && envsubst < docker-compose.template.yml > docker-compose.yml
```
---
### ğŸ§° Services
| Service     | Port | Description                            |
| ----------- | ---- | ---------------------------------------|
| Airflow UI  | 8080 | Orchestration du pipeline              |
| MLflow      | 5000 | Tracking des expÃ©riences               |
| API FastAPI | 8000 | Endpoint de prÃ©diction                 |
| PostgreSQL  |      | Backend Airflow & MLflow               |
| Redis       |      | Message broker Airflow (Celery)        |
| Prometheus  | 9090 | Monitoring des mÃ©triques API           |
| Grafana     | 3000 | Visualisation des mÃ©triques Prometheus |

---
### â–¶ï¸ Lancer lâ€™environnement
1. PrÃ©requis

    docker installÃ©

    Un fichier .env avec les variables suivantes : 
    ```
    # Description: Environment variables for the Rakuten project
    # The account must be subscribed to the challenge https://challengedata.ens.fr/participants/challenges/35/
    ENSDATA_LOGIN=
    ENSDATA_PASSWORD=

    # The path to the directory where the data is stored
    DATA_RAW_DIR="./data/raw"
    # The path to the directory where the the images of train dataset are stored
    DATA_RAW_IMAGES_TRAIN_DIR="./data/raw/image_train"
    # The path to the directory where the the images of test dataset are stored
    DATA_RAW_IMAGES_TEST_DIR="./data/raw/image_test"

    # The path to the directory where the processed data will be stored
    DATA_PROCESSED_DIR="./data/processed"
    # The path to the directory where the model will be stored
    MODEL_DIR="./models"
    # The path to the directory where the logs will be stored
    LOGS_DIR="./logs"
    # The path to the directory where the scores of model evaluation will be stored
    METRICS_DIR="./metrics"

    # Definition of the secret key for signing JWT tokens
    # This key should be kept secret and not shared publicly
    # It is used to ensure the integrity and authenticity of the JWT tokens
    # It is recommended to use a strong, random key for production environments

    JWT_SECRET_KEY = 

    FERNET_KEY=

    # Local directory where is stored the projet
    BASE_DIR = 

    # The Dockerfile to use for training the model
    # If GPU is available, then set Dockerfile.evaluate_gpu
    DOCKERFILE_TRAIN=docker/Dockerfile.train

    # The Dockerfile to use for evaluating the model
    # If GPU is available, then set Dockerfile.evaluate_gpu
    DOCKERFILE_EVALUATE=docker/Dockerfile.evaluate

    # The Dockerfile to use for launching API rest with the model
    # If GPU is available, then set Dockerfile.api_gpu
    DOCKERFILE_API=docker/Dockerfile.api
    ```
2. Lancement des services
    ```
    docker compose up --build
    ```
    Airflow sera accessible sur localhost:8080, et MLflow sur localhost:5000.
    Prometheus sera accessible sur http://localhost:9090
    (Permet de visualiser les mÃ©triques exposÃ©es par lâ€™API ou Airflow via /metrics)
    Grafana sera accessible sur http://localhost:3000 (Identifiants par dÃ©faut : admin / admin)

---
### âš™ï¸ Pipelines Airflow

Le DAG principal (rakuten_dags.py) orchestre les Ã©tapes suivantes :
- data_loading_task
- preprocessing_task
- training_task
- evaluation_task
- mlflow_dag_task

---
### ğŸ§ª Suivi des expÃ©riences

Les logs et artefacts d'entraÃ®nement sont automatiquement tracÃ©s dans MLflow :

```http://localhost:5000 ```

Le tracking inclut :
- mÃ©triques dâ€™Ã©valuation
- paramÃ¨tres du modÃ¨le
- visualisations

---
### ğŸŒ API de prÃ©diction

Un service FastAPI expose un endpoint sur le port 8000.

---
### ğŸ§ª Tests et reproductibilitÃ©

Les composants sont encapsulÃ©s dans des images Docker distinctes pour chaque Ã©tape (dataloading, preprocessing, etc.), facilitant lâ€™isolation et les tests.

---
### ğŸ—‚ï¸ Gestion des donnÃ©es avec DVC

Les transformations sont suivies avec DVC pour permettre une versioning des datasets transformÃ©s.
```
dvc repro
dvc push
``` 

---
### ğŸ“Š Monitoring avec Prometheus et Grafana
Lâ€™API FastAPI est instrumentÃ©e avec `prometheus_fastapi_instrumentator` pour exposer des mÃ©triques accessibles sur :

```
http://localhost:8000/metrics
```

ğŸ” Prometheus

Prometheus collecte les mÃ©triques de lâ€™API toutes les 15 secondes.
Interface accessible via :

```
http://localhost:9090
```

Exemple de requÃªte PromQL Ã  exÃ©cuter dans lâ€™interface :

```
sum by (handler) (http_requests_total)
```

Cela permet de visualiser le nombre total de requÃªtes par endpoint.


ğŸ“ˆ Grafana

Grafana permet de crÃ©er des dashboards personnalisÃ©s Ã  partir des donnÃ©es Prometheus.
AccÃ¨s Ã  Grafana :

```
http://localhost:3000
```

Identifiants par dÃ©faut :
	â€¢	Login : admin
	â€¢	Mot de passe : admin

Pour configurer :
	1.	Aller dans â€œConnections > Data sourcesâ€.
	2.	Cliquer sur â€œAdd data sourceâ€.
	3.	SÃ©lectionner Prometheus.
	4.	Renseigner lâ€™URL : http://prometheus:9090.
	5.	CrÃ©er des panels Ã  partir de requÃªtes PromQL (ex: http_requests_total).

---
### âœ… Tests unitaires

Le rÃ©pertoire tests/ contient des tests unitaires pour valider les diffÃ©rentes Ã©tapes du pipeline ML : chargement des donnÃ©es, prÃ©traitement, entraÃ®nement, prÃ©diction, etc.
ğŸ“¦ Structure
```
tests/
â”œâ”€â”€ test_dataloading.py
â”œâ”€â”€ test_preprocessing.py
â”œâ”€â”€ test_training.py
â”œâ”€â”€ test_evaluation.py
â””â”€â”€ conftest.py  # Fixtures partagÃ©es 
```
â–¶ï¸ ExÃ©cution des tests

Assure-toi dâ€™avoir installÃ© pytest (via pip install pytest ou via un requirements.txt), puis lance les tests avec :
```
python -m pytest
```

### Installation k3s
Lancer le script :
```
./scripts/install_k3s.sh
```

### DÃ©ployer l'api sur k3s et le monitoring
Lancer les scripts
```
./scripts/deploy_k3s.sh
./scripts/deploy_monitoring.sh
```

### Nettoyer les ressources k3s (namespace, pv/pvc, pods)
Lancer les scripts
```
./scripts/cleanup_monitoring.sh
./scripts/cleanup_k3s.sh
```

---
### ğŸ“ Auteurs

- Olivier ISNARD
- Christian SEGNOU

EncadrÃ©s dans le cadre de la formation MLOps par Maria de DataScientest.
